---
title: "Stat M254 Homework 1"
subtitle: Due Apr 27 @ 11:59PM
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

```{r}
library(tidyverse)
library(dplyr)
library(Seurat)
library(patchwork)
library(Matrix)
library(VennDiagram)
library(sctransform)
library(ggplot2)
```

# Part 1: Real data \[using the data from pbmc.csv\]

## Problem 1

![](images/WeChatf650912980d35a374b4d90976f5aebc5.png)

```{r}
cell_meta <- read.csv("data/pbmc.csv", row.names = 1)
```

```{r}
# metric 1
pbmc1 <- CreateSeuratObject(counts = cell_meta, project = "pbmc", 
                           min.features = 200)
pbmc1
```

```{r}
pbmc <- CreateSeuratObject(counts = cell_meta, project = "pbmc")
```

```{r}
# metric 2
pbmc2 <- subset(pbmc, subset = nFeature_RNA > 300 & nFeature_RNA < 10000)
pbmc2
```

```{r}
# metric 3
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")
pbmc3 <- subset(pbmc, subset = percent.mt < 15)
pbmc3
```

**Answer:** `Metric 1(UMI)` filtered 100 samples. `Metric 2(gene occurrance)` filtered 297 samples. `Metric 3(mitochondrial reads)` filterd 56 samples.

## Problem 2

![](images/WeChatf17b4969d837624e2df0da039cf53fef.png)

```{r}
allcells <- colnames(pbmc)
QC1 <- colnames(pbmc1)
QC2 <- colnames(pbmc2)
QC3 <- colnames(pbmc3)

cells1 <- setdiff(allcells, QC1)
cells2 <- setdiff(allcells, QC2)
cells3 <- setdiff(allcells, QC3)
```

```{r}
grid.newpage()
# Draw a Venn diagram for the three sets of cell identifiers
venn.plot <- draw.triple.venn(
  area1 = length(cells1),
  area2 = length(cells2),
  area3 = length(cells3),
  n12 = length(intersect(cells1, cells2)),
  n23 = length(intersect(cells2, cells3)),
  n13 = length(intersect(cells1, cells3)),
  n123 = length(Reduce(intersect, list(cells1, cells2, cells3))),
  category = c("QC method 1", "QC method 2", "QC method 3"),
  fill = c("red", "blue", "green")
)

grid.draw(venn.plot)


```

**Answer:**

All these three methods filtered out some similar cells but they also filtered dissimilar cells. In particular,

-   `QC method 1` and `QC method 2` filtered out the 100 same cells

-   `QC method 1` and `QC method 3` filtered out the 6 same cells

-   `QC method 2` and `QC method 3` filtered out the 9 same cells

-   `QC method 1` filtered out 47 cells which are not filtered by `QC method 2` and `QC method 3`

-   `QC method 2` filtered out 194 cells which are not filtered by `QC method 1` and `QC method 3`

-   `QC method 3` did not filter out any cells which are not filtered by `QC method 1` and `QC method 2`

It is reasonable that cells filtered by `QC method 1` and `QC method 2` are similar because total UMI counts sums up UMI count in all genes and cells with less genes are likely to have less total UMI counts. It also makes sense that cells filtered by `QC method 3` are likely dissimilar to the other 2 QC methods since mitochondrial reads are not directly related to UMI counts or gene occurrance.

## Problem 3

![](images/WeChata72b8237e39ad531061149bf56619ae3.png)

```{r}
log1pPF = function(counts){
  ls = colSums(counts)
  meanLS = mean(ls)
  mat = t(log1p(apply(counts, 1, function(x){x/ls * meanLS})))
  return(mat)
}
```

```{r}
#filter data
pbmc <- CreateSeuratObject(counts = cell_meta, project = "pbmc", 
                           min.cells = 10, min.features = 200)

pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")

pbmc_filtered <- subset(pbmc, subset = nFeature_RNA > 300 & nFeature_RNA < 10000 
               & percent.mt < 15)

```

```{r}
pbmc_filtered
```

```{r}
# Normalize the data
pbmc_norm1 <- NormalizeData(pbmc_filtered, 
                            normalization.method = "LogNormalize", 
                            scale.factor = 10000)
pbmc_norm2 <- NormalizeData(pbmc_filtered, 
                            normalization.method = "LogNormalize", 
                            scale.factor = 1000000)
# run sctransform
pbmc_norm3 <- SCTransform(pbmc_filtered, variable.features.n = 15708, 
                          verbose = FALSE)

log1pPF = function(seurat_obj) {
  # Extracting the counts matrix from the Seurat object
  counts <- GetAssayData(seurat_obj, slot = "counts")
  
  # Calculate column sums of the counts matrix
  ls = colSums(counts)
  meanLS = mean(ls)
  
  # Normalize counts, log-transform, and transpose
  normalized_counts = t(counts) / ls * meanLS
  mat = t(log1p(normalized_counts))
  
  return(mat)
}

pbmc_norm4 <- log1pPF(pbmc_filtered)
pbmc_norm4 <- CreateSeuratObject(counts = pbmc_norm4, project = "pbmc")
```

## Problem 4

![](images/WeChat3eed95cc2facc961f47c0c6835db984a.png)



```{r}
library(gridExtra)

plotMVP <- function(SeuratObj, name, type){
  # Extract the counts matrix
  counts_matrix <- GetAssayData(SeuratObj, slot = type)
  counts_matrix <- as.matrix(counts_matrix)
  
  # Calculate the mean and variance of each gene
  gene_means = rowMeans(counts_matrix)
  gene_variances = apply(counts_matrix, 1, var) 
  
  # Create a scatter plot
  gene_data = data.frame(
    Mean = gene_means,
    Variance = gene_variances
  )
  
  p <- ggplot(gene_data, aes(x = Mean, y = Variance)) +
    geom_point(alpha = 0.5) +  # alpha for transparency if points overlap
    labs(x = "Mean Expression", y = "Gene Variance", 
         title = paste0("Mean vs Variance: ", name)) +
    theme_minimal()
  
  return(p)
}

p0 <- plotMVP(pbmc_filtered, "unNormalized", "counts")
p1 <- plotMVP(pbmc_norm1, "log1pCP10K", "data")
p2 <- plotMVP(pbmc_norm2, "log1pCP1M", "data")
p3 <- plotMVP(pbmc_norm3, "scTransform", "data")
p4 <- plotMVP(pbmc_norm4, "log1pPF", "counts")

p0 + p1 + p2 + p3 + p4
```
**Answer:**
It seems like all four normalization methods have shown some degrees of variance stabilization. In particular, 2 log scale transformations show strong variance stabilization. The plots show an arch shape which indicate that as mean increases, the variance initially increase and then drops quickly after a certain point. However, there are other concerns. We can see the variance gets close to 0 as mean increases for `log1pCP10K` and `log1pCP1M`. This could be a sign of so-called distribution collapsing, which detriment the power to detect meaningful variance after normalization. The `scTransform` method seems to be more robust. As mean increases, the variance initial increases and then shows an uniform pattern. The `log1pPF` method also shows a similar pattern as `scTransform`.

## Problem 5

![](images/WeChat6c0aece8171f2ba6c54569585bf81c39.png)
```{r}
pbmc_norm2
```

```{r}
# Function to calculate Spearman correlation between mean and variance of gene expression
calculateSpearman <- function(seurat_obj, type) {
  # Get the data
  data_matrix <- GetAssayData(seurat_obj, slot = type)
  data_matrix <- as.matrix(data_matrix)
  # Calculate mean and variance
  means = rowMeans(data_matrix)
  variances = apply(data_matrix, 1, var)
  
  # Calculate Spearman correlation
  correlation = cor(means, variances, method = "spearman")
  return(correlation)
}

# Calculate Spearman correlation for each normalization method
spearman_filtered <- calculateSpearman(pbmc_filtered, "counts") 
spearman_norm1 <- calculateSpearman(pbmc_norm1, "data")
spearman_norm2 <- calculateSpearman(pbmc_norm2, "data")
spearman_norm3 <- calculateSpearman(pbmc_norm3, "data") 
spearman_norm4 <- calculateSpearman(pbmc_norm4, "counts")

# Print the Spearman correlations
print(paste("Spearman correlation for unnormalized data:", spearman_filtered))
print(paste("Spearman correlation for log1pCP10K:", spearman_norm1))
print(paste("Spearman correlation for log1pCP1M:", spearman_norm2))
print(paste("Spearman correlation for scTransform:", spearman_norm3))
print(paste("Spearman correlation for log1pPF:", spearman_norm3))

```

# Part 2: Simulated data

## Problem 6

![](images/WeChat6145b34253d59f27bb4f5731346f3f1c.png)



### 1)

![](images/WeChat54abf928f531975f58842d5a7aa3cbcd.png)

```{r}
library(BayesTools)
#Simulate data

ncells = 1000
ngenes = 2000

library_size = read.csv("data/library-size.csv", row.names = 1)[, 1]
point_mass = read.csv("data/point-mass.csv", row.names = 1)[, 1]
Simulate_counts_1 = matrix(0, ngenes, ncells)
for(i in 1:ncells){
  Expression_model = rpoint(ngenes, location = point_mass)
  Simulate_counts_1[,i] = rpois(ngenes, 
                              lambda = library_size[i] * Expression_model)
}
```

**Answer:**

$X_{gc}\sim Poisson(x_{c+})$ for $\lambda_{gc}\geq \alpha_g$

### 2)

![](images/WeChatd8500ba3173f4917f9252442fb7730af.png)

```{r}
ncells = 1000
ngenes = 2000

#Simulate data
library_size = read.csv("data/library-size.csv", row.names = 1)[, 1]
shape_rate = read.csv("data/shape+rate.csv", row.names = 1)[, c(1, 2)]
Simulate_counts_2 = matrix(0, ngenes, ncells)
for(i in 1:ncells){
  Expression_model = rgamma(ngenes, rate = shape_rate[, 1], 
                            shape = shape_rate[, 2])
  Simulate_counts_2[,i] = rpois(ngenes, 
                              lambda = library_size[i] * Expression_model)
}
```

Since gamma distribution has the scaling property.

$x_{c+}\lambda_{gc}\sim Gamma(x_{c+}\alpha_g, \beta_g)$

$X_{gc}\sim NB(x_{c+}\alpha_g, \frac{\beta_g}{1+\beta_g})$

## Problem 7. Answering the following questions

### 1) Apply four different normalization methods in question 3 on each simulated dataset.

```{r}
sim1 <- CreateSeuratObject(counts = Simulate_counts_1)
sim2 <- CreateSeuratObject(counts = Simulate_counts_2)
```
```{r}
sim1_norm1 <- NormalizeData(sim1, 
                            normalization.method = "LogNormalize", 
                            scale.factor = 10000)
sim1_norm2 <- NormalizeData(sim1, 
                            normalization.method = "LogNormalize", 
                            scale.factor = 1000000)
# run sctransform
sim1_norm3 <- SCTransform(sim1, variable.features.n = 2000, 
                          verbose = FALSE)

sim1_norm4 <- log1pPF(sim1)
sim1_norm4 <- CreateSeuratObject(counts = sim1_norm4, project = "sim1")

sim2_norm1 <- NormalizeData(sim2, 
                            normalization.method = "LogNormalize", 
                            scale.factor = 10000)
sim2_norm2 <- NormalizeData(sim2, 
                            normalization.method = "LogNormalize", 
                            scale.factor = 1000000)
# run sctransform
sim2_norm3 <- SCTransform(sim2, variable.features.n = 2000, 
                          verbose = FALSE)

sim2_norm4 <- log1pPF(sim2)
sim2_norm4 <- CreateSeuratObject(counts = sim2_norm4, project = "sim2")

```

### 2) Draw 5 figures with gene means vs variances as in question 4 for each simulated dataset.

```{r}

p1 <- plotMVP(sim1_norm1, "log1pCP10K", "data")
p2 <- plotMVP(sim1_norm2, "log1pCP1M", "data")
p3 <- plotMVP(sim1_norm3, "scTransform", "data")
p4 <- plotMVP(sim1_norm4, "log1pPF", "counts")

p1 + p2 + p3 + p4
```
```{r}
p1 <- plotMVP(sim2_norm1, "log1pCP10K", "data")
p2 <- plotMVP(sim2_norm2, "log1pCP1M", "data")
p3 <- plotMVP(sim2_norm3, "scTransform", "data")
p4 <- plotMVP(sim2_norm4, "log1pPF", "counts")

p1 + p2 + p3 + p4
```

### 3) Use Spearman correlation to evaluate normalization methods as in question 5 for each simulated dataset.
```{r}
# Calculate Spearman correlation for each normalization method

spearman_norm1 <- calculateSpearman(sim1_norm1, "data")
spearman_norm2 <- calculateSpearman(sim1_norm2, "data")
spearman_norm3 <- calculateSpearman(sim1_norm3, "data") 
spearman_norm4 <- calculateSpearman(sim1_norm4, "counts")

# Print the Spearman correlations
print(paste("Spearman correlation for log1pCP10K:", spearman_norm1))
print(paste("Spearman correlation for log1pCP1M:", spearman_norm2))
print(paste("Spearman correlation for scTransform:", spearman_norm3))
print(paste("Spearman correlation for log1pPF:", spearman_norm3))
```

```{r}

# Calculate Spearman correlation for each normalization method

spearman_norm1 <- calculateSpearman(sim2_norm1, "data")
spearman_norm2 <- calculateSpearman(sim2_norm2, "data")
spearman_norm3 <- calculateSpearman(sim2_norm3, "data") 
spearman_norm4 <- calculateSpearman(sim2_norm4, "counts")

# Print the Spearman correlations
print(paste("Spearman correlation for log1pCP10K:", spearman_norm1))
print(paste("Spearman correlation for log1pCP1M:", spearman_norm2))
print(paste("Spearman correlation for scTransform:", spearman_norm3))
print(paste("Spearman correlation for log1pPF:", spearman_norm3))
```
```

